{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"River Hyperparameter Tuning with SPOT HTR\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Parameter Optimization\n",
    "## `river` Hyperparameter Tuning: HTR with User Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspot                                    0.0.1\n",
      "pyspotriver                               0.0.3\n",
      "pyspotstream                              0.2.0\n",
      "spotPython                                0.0.6\n",
      "spotRiver                                 0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade build\n",
    "# !{sys.executable} -m pip install --upgrade --force-reinstall http://www.gm.fh-koeln.de/~bartz/site/spotPython.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: HTR Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import inf\n",
    "from spotRiver.fun.hyperriver import HyperRiver\n",
    "from spotPython.spot import spot\n",
    "from spotRiver import data\n",
    "from scipy.optimize import shgo\n",
    "from scipy.optimize import direct\n",
    "from scipy.optimize import differential_evolution\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 The Objective Function \n",
    "\n",
    "* Here we will use the river `HATR` function.\n",
    "* First, the function will be tested independently from `Spot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "from river import datasets\n",
    "from river import time_series\n",
    "from river import utils\n",
    "import calendar\n",
    "import math\n",
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "from river import metrics\n",
    "from spotRiver.fun.hyperriver import HyperRiver\n",
    "\n",
    "fun = HyperRiver(123).fun_HTR_iter_progressive\n",
    "var_type = [\"int\"] * 2 + [\"num\"] * 2 + [\"factor\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 The `fun_snarimax` from `spotPython`'s `HyperRiver` class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, we use the implementation of the function from the `HyperRiver` class.\n",
    "* Twelve hyperparameters to be optimized. Here:\n",
    "\n",
    "0. `p` (int):\n",
    "    Order of the autoregressive part.\n",
    "    This is the number of past target values that will be included as features.\n",
    "1. `d` (int):\n",
    "    Differencing order.\n",
    "2. `q` (int):\n",
    "    Order of the moving average part.\n",
    "    This is the number of past error terms that will be included as features.\n",
    "3. `m` (int):\n",
    "    Season length used for extracting seasonal features.\n",
    "    If you believe your data has a seasonal pattern, then set this accordingly.\n",
    "    For instance, if the data seems to exhibit a yearly seasonality,\n",
    "    and that your data is spaced by month, then you should set this to `12`.\n",
    "    Note that for this parameter to have any impact you should also set\n",
    "    at least one of the `p`, `d`, and `q` parameters.\n",
    "4. `sp` (int):\n",
    "    Seasonal order of the autoregressive part.\n",
    "    This is the number of past target values that will be included as features.\n",
    "5. `sd` (int):\n",
    "    Seasonal differencing order.\n",
    "6. `sq`(int):\n",
    "    Seasonal order of the moving average part.\n",
    "    This is the number of past error terms that will be included as features.\n",
    "7. `lr` (float):\n",
    "    learn rate of the linear regression model. A river `preprocessing.StandardScaler`\n",
    "    piped with a river `linear_model.LinearRegression` will be used.\n",
    "8. `intercept_lr` (float): intercept of the the linear regression model.\n",
    "    A river `preprocessing.StandardScaler` piped with a river `linear_model.LinearRegression`\n",
    "    will be used.\n",
    "9. `hour` (bool): If `True`, an hourly component is added.\n",
    "10. `weekday` (bool): If `True`, an weekday component is added.\n",
    "11. `month` (bool): If `True`, an monthly component is added."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: Instead of using the Airline Passenger data as in notebook 01, we demonstrate the usage of user specified data which is *not* part of the `spotRiver` package!\n",
    "* Remember: Previously, we used the setting, which will be overwritten in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 p, d, q, m, sp, sd, sq, lr, intercept_lr, hour, weekday, month:\n",
    "# lower = np.array([0, 0, 0, 1, 0,  0,  0,   0.00225, 0.05,   0,        0,   0])\n",
    "# upper = np.array([1, 1, 1, 24, 1,  1,   1,  0.0025, 0.1,    0,        0,   1])\n",
    "# fun_control = {\"horizon\": 12,\n",
    "#                \"grace_period\": None,\n",
    "#                \"data\": dataset,\n",
    "#                }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Specified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspotstream.datasets import fetch_opm\n",
    "# ds = fetch_opm(include_categorical=False, data_home=\"data\", return_X_y=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Important: Specify the location of your data, e.g., `/home/data/` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotRiver.data.generic import GenericData\n",
    "dataset = GenericData(filename=\"opm_cat.csv\",\n",
    "                      directory=\".\",\n",
    "                      target=\"Sale Amount\",\n",
    "                      n_features=14,\n",
    "                      n_samples=195_832,\n",
    "                      converters={'List Year': int,\n",
    "                                  'Assessed Value': float,\n",
    "                                  'Sale Amount': float,\n",
    "                                  'Sales Ratio': float,\n",
    "                                  'lon': float,\n",
    "                                  'lat': float,\n",
    "                                  'timestamp_rec': float},\n",
    "                      parse_dates=None\n",
    "                      # parse_dates={\"Date Recorded\": \"%Y-%m-%d\"}\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'List Year': 2001, 'Assessed Value': 107530.0, 'Sales Ratio': 0.575026738, 'lat': 41.50021401170393, 'lon': -72.87396263711757, 'timestamp_rec': 1001894400.0, 'Town': 'Bristol', 'Address': \"MULTI #'S CONSTANCE LN\", 'Property Type': 'Unknown', 'Residential Type': 'Unknown', 'Non Use Code': 'Unknown', 'Assessor Remarks': 'Unknown', 'OPM remarks': 'Unknown'} 187000.0\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset:\n",
    "    print(x,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "lower = np.array([100, 2,  1e-8, 0.025, 0])\n",
    "upper = np.array([200, 10, 1e-6, 0.075, 2])\n",
    "fun_control = {\"data\": dataset}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Run the `Spot` Optimizer\n",
    "\n",
    "* Since the data is larger than the airline passengers data, the max. time is increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: [##########] 100.00% Done...\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "spotPython tuning: [##########] 100.00% Done...\n",
      "spotPython tuning: [#########-] 89.26% \r"
     ]
    }
   ],
   "source": [
    "spot_htr = spot.Spot(fun=fun,\n",
    "                   lower = lower,\n",
    "                   upper = upper,\n",
    "                   fun_evals = inf,\n",
    "                   fun_repeats = 1,\n",
    "                   max_time = 1,\n",
    "                   noise = False,\n",
    "                   tolerance_x = np.sqrt(np.spacing(1)),\n",
    "                   var_type=var_type,\n",
    "                   infill_criterion = \"y\",\n",
    "                   n_points = 1,\n",
    "                   seed=123,\n",
    "                   log_level = 50,\n",
    "                   show_models= False,\n",
    "                   show_progress= True,\n",
    "                   fun_control = fun_control,\n",
    "                   design_control={\"init_size\": 10,\n",
    "                                   \"repeats\": 1},\n",
    "                   surrogate_control={\"noise\": False,\n",
    "                                      \"cod_type\": \"norm\",\n",
    "                                      \"min_theta\": -4,\n",
    "                                      \"max_theta\": 3,\n",
    "                                      \"n_theta\": 5,\n",
    "                                      \"model_optimizer\": differential_evolution,\n",
    "                                      \"model_fun_evals\": 1000,\n",
    "                                      })\n",
    "spot_htr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Results \n",
    "\n",
    "* Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_htr.print_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = spot_htr.k\n",
    "for i in range(n-1):\n",
    "    for j in range(i+1, n):\n",
    "        spot_htr.plot_contour(i=i, j=j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Evaluate SNARIMAX Model with Tuned Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spot_htr.to_all_dim(spot_htr.min_X.reshape(1,-1))\n",
    "print(X)\n",
    "p = X[:, 0]\n",
    "d = X[:, 1]\n",
    "q = X[:, 2]\n",
    "m = X[:, 3]\n",
    "sp = X[:, 4]\n",
    "sd = X[:, 5]\n",
    "sq = X[:, 6]\n",
    "lr = X[:, 7]\n",
    "intercept_lr = X[:, 8]\n",
    "hour = X[:, 9]\n",
    "weekday = X[:,10]\n",
    "month = X[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotRiver.utils.features import get_weekday_distances\n",
    "from spotRiver.utils.features import get_ordinal_date\n",
    "from spotRiver.utils.features import get_month_distances\n",
    "from spotRiver.utils.features import get_hour_distances\n",
    "h_i = int(hour)\n",
    "w_i = int(weekday)\n",
    "m_i = int(month)\n",
    "# baseline:\n",
    "extract_features = compose.TransformerUnion(get_ordinal_date)\n",
    "if h_i:\n",
    "    extract_features = compose.TransformerUnion(get_ordinal_date,\n",
    "                                                get_hour_distances)\n",
    "if w_i:\n",
    "    extract_features = compose.TransformerUnion(extract_features,\n",
    "                                                get_weekday_distances)\n",
    "if m_i:\n",
    "    extract_features = compose.TransformerUnion(extract_features,\n",
    "                                                get_month_distances)\n",
    "model = compose.Pipeline(\n",
    "    (\"extraction\", extract_features),\n",
    "    (\"ts\", time_series.SNARIMAX(\n",
    "        p=int(p),\n",
    "        d=int(d),\n",
    "        q=int(q),\n",
    "        m=int(m),\n",
    "        sp=int(sp),\n",
    "        sd=int(sd),\n",
    "        sq=int(sq),\n",
    "        regressor=compose.Pipeline(\n",
    "            (\"prep\", preprocessing.StandardScaler()),\n",
    "            (\"lm\", linear_model.LinearRegression(\n",
    "                intercept_init=0,\n",
    "                optimizer=optim.SGD(float(lr)),\n",
    "                intercept_lr=float(intercept_lr),\n",
    "            )),\n",
    "        ),\n",
    "    )),\n",
    ")\n",
    "# eval\n",
    "metric = metrics.MAE()\n",
    "res = time_series.evaluate(fun_control[\"data\"], model, metric, horizon=fun_control[\"horizon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = res.metrics\n",
    "z = 0.0\n",
    "for j in range(len(y)):\n",
    "    z = z + y[j].get()\n",
    "z / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"ts\"].regressor[\"lm\"].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.forecast(horizon=fun_control[\"horizon\"])\n",
    "forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
